---
会议: 29th USENIX Security Symposium
时间: "2020"
---
# 摘要

视频分析即服务正成为云服务提供商的一项重要服务。此类服务中的一个关键关注点是所分析视频的隐私性。虽然**可信执行环境**（TEEs）是防止私人视频内容直接泄露的具有潜力的选项，但它们仍然容易受到**侧信道攻击**的威胁。

我们介绍了一套名为Visor的系统，该系统在云平台被破坏或存在不可信共享租户的情况下，为用户视频流和机器学习模型提供了保密性。Visor在CPU和GPU上共同构成的可信执行环境（TEE）中执行视频流水线。它通过防止由视频模块的数据依赖访问模式引发的侧信道攻击，保护了流水线的安全性，并且解决了CPU-GPU通信通道中的泄露问题。相比于简单的盲目解决方案，Visor的速度快了多达1000倍，并且相对于非盲目的基线系统的开销仅限于2倍到6倍之间。Visor系统旨在确保在云平台安全风险下的用户视频流和机器学习模型的安全，通过在CPU和GPU的混合可信执行环境中执行视频处理流程，有效防止了由数据访问模式引发的侧信道攻击，同时解决了CPU与GPU间通信通道中的信息泄露问题。相较于其他盲目解决方案，Visor展现出极高的性能优势，其相对于非盲目的基线系统的额外开销保持在较低范围，仅为2至6倍之间，这使得Visor成为在云环境下提供高效、安全视频处理服务的理想选择。

# 1 介绍

摄像机因其支持的众多应用（如交通规划、零售体验和企业安全[97, 104, 105]）而被广泛部署。来自摄像机的视频被流式传输到云端，在那里使用由计算机视觉技术（例如 OpenCV [77]）和卷积神经网络（例如目标检测 CNN [83]）组成的视频分析流水线进行处理[44, 48, 115]；如图 1 所示。事实上，“视频分析即服务”正成为云提供商的一项重要产品[63, 2]。


>[!notion]- 图1
![[Pasted image 20250919185938.png]]
>  *视频分析流程。流程(a)采用视觉算法提取目标，并在GPU上使用CNN分类器对裁剪后的目标进行分类。流程(b)同样使用视觉算法作为过滤器，但将整个帧发送至CNN检测器。两种流程均可选配目标跟踪功能。*


视频内容的隐私是“视频分析即服务”产品中的首要关注点。视频通常包含敏感信息，例如用户的家庭内部、工作场所中的人员或汽车车牌。例如，Kuna 家庭监控服务[51]将用户家中的视频传输到云端，分析视频，并在检测到感兴趣区域有移动时通知用户。为了用户隐私，视频流必须保持*机密性*，不得泄露给云提供商或云中的其他共租户。

可信执行环境（TEE）[61, 107]非常适合在云端进行隐私保护视频分析。与同态加密等加密方法相比，TEE 依赖于云租户也信任硬件的假设。硬件提供了创建安全“**飞地**”的能力，这些飞地受到保护，免受特权攻击者的侵害。TEE 比密码技术更具吸引力，因为它们的速度要快几个数量级。事实上，CPU TEE（例如 Intel SGX [61]）是机密云计算的核心[62, 39]。同时，GPU TEE 的最新进展[41, 107]也使得能够以强大的隐私保证执行 ML 模型（例如神经网络）。因此，CPU 和 GPU TEE 为构建隐私保护视频分析系统提供了机会。

不幸的是，TEE（例如 Intel SGX）容易受到一系列侧信道攻击（例如[12, 13, 109, 111]）。例如，在 §2.3 中，我们展示了仅通过观察广泛使用的边界框检测 OpenCV 模块的内存访问模式，攻击者就可以推断出视频中*所有运动物体的精确形状和位置*。通常，攻击者可以推断出关于正在处理的视频的关键信息，例如有活动的时间、出现在视频帧中的物体，所有这些信息与摄像机覆盖的物理空间知识相结合，可能导致严重的机密性侵犯。

我们提出了 Visor，一个用于隐私保护视频分析服务的系统。Visor 保护正在分析的视频的机密性，使其不被服务提供商和其他共租户获取。当租户在云端托管自己的 CNN 模型时，它还保护模型参数和权重。Visor 能够抵御强大的飞地攻击者，该攻击者可以破坏飞地外的软件栈，并通过侧信道观察对网络、磁盘或内存的任何*数据依赖性访问*（类似于先前的工作[82, 75]）。

Visor 做出了两个主要贡献，结合了来自 ML 系统、安全、计算机视觉和算法设计的见解。首先，我们提出了一个用于机器学习即服务（MLaaS）的隐私保护框架，该框架支持跨 CPU 和 GPU 资源的基于 CNN 的 ML 应用。我们的框架有潜力支持视频分析之外的应用，例如医学成像、推荐系统和金融预测。其次，我们在我们的 MLaaS 框架内为常用视觉模块开发了新颖的**数据不可见算法**，并具有可证明的隐私保证。这些模块高效且可以组合起来构建许多不同的视频分析流水线。在设计我们的算法时，我们制定了一套设计原则，这些原则也可以广泛适用于其他视觉模块。

#### 1) Privacy-Preserving MLaaS Framework

Visor 利用了一个*混合* TEE，该 TEE 跨越了云中可用的 CPU 和 GPU 资源。最近的工作表明，扩展视频分析流水线需要明智地使用 CPU 和 GPU [36, 80]。一些流水线模块可以在所需帧速率下在 CPU 上运行（例如，视频解码或视觉算法），而其他模块（例如 CNN）则需要 GPU，如图 1 所示。因此，我们的解决方案跨越了 CPU 和 GPU TEE，并将它们组合成一个统一的信任域。

Visor 系统地解决了混合 TEE 各个组件中基于访问模式的泄漏，从视频摄取到 CPU-GPU 通信，再到 CNN 处理。具体来说，我们采取了以下步骤：
	a) Visor 利用一套**数据不可见原语**来消除 CPU TEE 中的访问模式泄漏。这些原语使得能够开发具有可证明隐私保证的不可见模块，这些模块的访问模式始终独立于私有数据。
	b) Visor 依赖一种新颖的**不可见通信协议**来消除 CPU-GPU 通道中的泄漏。由于 CPU 模块充当过滤器，CPU-GPU 通道中的数据流（每个帧的对象通过该通道传递给 GPU）会泄漏关于每个帧内容的信息，使攻击者能够推断出一个帧中运动物体的数量。在高层次上，Visor 用虚拟对象填充该通道，利用我们的应用程序不受 CPU-GPU 带宽限制这一观察结果。为了减少 GPU 浪费，Visor 智能地最小化对虚拟对象运行 CNN 的情况。
	c) Visor 通过利用**无分支 CUDA 指令**以数据不可见的方式实现条件操作（例如 ReLU 和最大池化），使得在 GPU TEE 中运行的 CNN 变得不可见。

#### 2) Efficient Oblivious Vision Pipelines.

接下来，我们为视频分析基础性的视觉模块设计了新颖的数据不可见算法，并使用上述框架提供的不可见原语实现了它们。视觉算法在视频分析流水线中用于提取运动的前景对象。这些算法（例如，背景减除、边界框检测、对象裁剪和跟踪）在 CPU 上运行，并作为廉价的过滤器来丢弃帧，而不是为每个帧的对象在 GPU 上调用昂贵的 CNN（更多内容见 §2.1）。这些模块可以组合起来构建各种视觉流水线，例如医学成像和运动跟踪。

正如我们在 §8 中演示的那样，使这些算法数据不可见的朴素方法（例如，使其操作独立于每个像素的值）可能会使视频流水线减慢几个数量级。相反，我们为视频分析流水线中的每个模块精心设计了不可见视觉算法，包括流行的 VP8 视频解码器[5]。我们的首要目标是将每个算法转换为一种对每个像素进行相同处理的模式。为了有效地应用这种设计模式，我们根据视觉模块的特性设计了一套算法和系统优化策略，如下所述。首先，我们采用**分治法**——即，我们根据功能将每个算法分解为独立的子例程，并单独定制每个子例程。其次，我们将顺序算法转换为一种形式，该形式在扫描输入图像的同时对每个像素执行相同的操作。第三，相同的像素操作允许我们在每个算法中系统地将处理成本分摊到像素组上。对于每个视觉模块，我们结合这些设计策略推导出应用于每个像素的操作。总的来说，这些策略比朴素的不可见解决方案性能提高了高达 1000 倍。我们在 §5 中更详细地讨论了我们的方法；然而，我们注意到，它也有可能为其他不可见视觉模块的设计提供信息，而不仅仅是我们在 Visor 中考虑的那些。

此外，正如先前的工作所示，加密网络流量的比特率变化也可能泄漏有关底层视频流的信息[88]，这超出了云端的访问模式泄漏。为了防止这种泄漏，我们修改了视频编码器，以在源端仔细地填充视频流，以优化视频解码器的延迟。因此，Visor 为私有视频分析提供了一个端到端的解决方案。

此外，如先前研究所示，加密网络流量中的比特率变化也可能泄露关于底层视频流的信息[88]，而不仅仅是云端的访问模式泄露。为了防止这种泄露，我们修改了视频编码器，在源头对视频流进行精心填充，以优化视频解码器的延迟。因此，Visor提供了一种端到端的私有视频分析解决方案。

**评估要点**。我们已在英特尔SGX CPU安全域[61]和格鲁吉特GPU安全域[107]上实现了Visor。我们使用包含敏感数据的商业城市视频流和数据中心场域视频流对Visor进行评估。评估结果表明，Visor的视觉组件性能较朴素 oblivious 解决方案提升高达1000倍，较当前最先进的通用 oblivious 程序执行系统提升6至7个数量级。与 non-oblivious 基线相比，Visor的开销被限制在2倍至6倍之间，这仍使我们能够在测试平台上实时分析多个视频流。Visor具有通用性，可适配现实应用中不同视觉组件的组合。因此，Visor为隐私视频分析提供了高效的解决方案。

# 2 背景与动机

## 2.1 视频分析即服务
图1展示了视频分析的典型流水线 [36, 48, 64, 114, 115]。客户端（例如源摄像头）将视频流发送到托管在云中的服务，该服务 (a) 将视频解码为帧，(b) 使用视觉算法从帧中提取对象，以及 (c) 使用预训练的卷积神经网络（CNN）对对象进行分类。摄像头通常提供控制视频流编码分辨率和帧率的能力。

>[!notion]- 图1
![[Pasted image 20250919185938.png]] 
>  *视频分析流程。流程(a)采用视觉算法提取目标，并在GPU上使用CNN分类器对裁剪后的目标进行分类。流程(b)同样使用视觉算法作为过滤器，但将整个帧发送至CNN检测器。两种流程均可选配目标跟踪功能。*

最近的研究表明，扩展视频分析流水线需要明智地使用 CPU 和 GPU [36, 80]。在 Visor 中，我们遵循微软 Rocket 视频分析平台 [64, 65] 的示例——我们通过在 CPU 上运行视频解码和视觉模块，同时将 CNN 卸载到 GPU 上来拆分流水线（如图1所示）。视觉模块处理每一帧，使用背景减除 [9] 检测视频中移动的“前景”对象，计算每个对象的边界框 [95]，并将它们从帧中裁剪出来以供 CNN 分类器使用。这些视觉模块即使在 CPU 上也能维持视频的典型帧率，从而作为重要的“过滤器”来减少 GPU 上昂贵的 CNN 操作 [36, 48]，因此在实际部署中被广泛使用。例如，图1(a)中的 CNN 分类仅在帧中感兴趣区域检测到移动对象时才会被调用。可选地，移动对象也会被跟踪以推断方向（例如，左转的汽车）。CNN 可以是如图1(a)所示的对象分类器（例如 ResNet [35]）；或者是如图1(b)所示的对象检测器（例如 Yolo [83]），它们将整个帧作为输入。流水线模块的选择取决于应用程序 [36, 44]，而 Visor 的目标是为所有流水线模块、它们的不同组合以及视觉 CNN 提供机密性。

虽然我们的描述侧重于多租户云服务，但我们的想法同样适用于多租户*边缘计算*系统，例如在蜂窝基站 [23]。在摄像头上使用轻量级可编程性技术以减少网络流量（例如，使用智能编码器 [106] 或动态调整帧率 [3]）与 Visor 的技术是正交的。

## 2.2 可信执行环境

可信执行环境（TEE），或称飞地（enclave），保护应用程序的代码和数据免受系统中所有其他软件的侵害。加载到飞地（CPU 和 GPU TEE）中的代码和数据可以通过**远程认证功能**由客户端验证。

**Intel SGX** [61] 在 CPU 上启用 TEE，并通过将飞地代码和数据存储在称为飞地页面缓存（EPC）的保护内存区域中来强制执行隔离。硬件确保飞地外的任何软件都无法访问 EPC 内容。

**Graviton** [107] 在与托管在 CPU TEE 中的可信应用程序协同工作时，在 GPU 上启用 TEE。Graviton 防止对手观察或篡改传输到/来自 GPU 的流量（数据和命令）。托管在 CPU TEE 中的可信 GPU 运行时（例如 CUDA 运行时）证明所有代码/数据都已安全加载到 GPU 上。

## 2.3 基于访问模式泄漏的攻击

TEE 容易受到利用微架构侧信道 [12, 13, 20, 29, 34, 54, 67, 89, 90]、基于软件的通道 [14, 111] 或应用程序特定泄漏（如网络和内存访问）的侧信道攻击的泄漏。

这些攻击中的很大一部分利用了**数据依赖的内存访问模式**（例如，分支预测、缓存计时或受控页面错误攻击）。Xu 等人 [111] 表明，通过简单地观察图像解码器的页面访问模式，攻击者可以重建整个图像。我们自己分析了缓存行粒度 [12, 29, 67, 90] 的访问模式泄漏对边界框检测算法 [95] 的影响（见图1(a)；§2.1）。我们通过捕获算法执行期间的内存访问轨迹来模拟现有攻击，然后检查该轨迹以逆向工程输入帧的内容。由于图像在内存中的布局是可预测的，我们发现攻击者能够推断出执行期间触及的所有像素的位置，从而推断出*所有对象的形状和位置*（如图2所示）。对象的形状和位置是任何视频的核心内容，并允许攻击者推断敏感信息，例如患者访问私人医疗中心的时间或居民在房屋内的时间，甚至可以根据其大小和形状推断个体是婴儿还是坐轮椅。事实上，与最大公共云提供商之一的客户的对话确实证实，*视频的隐私性*是他们注册视频分析云服务时*最关心的两个问题之一*。

>[!notion]- 图2
>攻击者通过边界框检测模块中的访问模式泄露，获取了所有帧对象（右侧）。
>![[Pasted image 20250919193937.png]] 

# 3 威胁模型与安全保障

我们描述攻击者的能力，并列出我们工作中在范围和不在范围的攻击。

## 3.1 硬件 Enclave 与侧信道

我们的可信计算基包括：（_i_）GPU 封装及其 enclave 实现，（_ii_）CPU 封装及其 enclave 实现，以及（_iii_）视频分析流水线实现和托管在 CPU enclave 中的 GPU 运行时。

Visor 的设计不依赖于任何特定的硬件 enclave；相反，Visor 建立在一个硬件 enclave 的 _抽象_ 模型之上，其中攻击者控制 enclave 外部的服务器软件栈（包括操作系统），但无法执行任何攻击来从处理器内部（包括处理器密钥）收集信息。攻击者还可以观察内存中所有（加密的）页面的内容和访问模式，包括数据和代码。我们假设攻击者可以在缓存行粒度上观察 enclave 的内存访问模式 [75]。请注意，我们的攻击者模型包括云服务提供商以及其他共同租户。

我们使用广泛部署的 Intel SGX enclave 来实例化 Visor。然而，最近的攻击表明，SGX 并不完全满足 Visor 所需的抽象 enclave 模型。例如，攻击者可能能够区分缓存行内的内存访问 [68, 113]。在 Visor 中，我们通过禁用底层系统中的超线程来缓解这些攻击，阻止攻击者观察核心内的侧信道；客户端可以在远程认证期间验证超线程已禁用 [4]。人们也可以采用补充性的解决方案来关闭基于超线程的攻击 [76, 18]。

其他违反我们抽象 enclave 模型的攻击不在考虑范围内：例如基于时序分析或功耗分析的攻击 [69, 96]、DoS 攻击 [32, 42] 或回滚攻击 [78]（这些都有补充性的解决方案 [10, 60]）。瞬态执行攻击（例如 [81, 89, 80, 13, 87, 101, 102, 103]）也不在范围内；这些攻击违反了 SGX 的威胁模型，并且通常由供应商通过微码更新及时修补。将来，人们可以在我们的实现中将 Intel SGX 替换为即将出现的 enclave，例如 MI6 [8] 和 Keystone [53]，它们解决了 SGX 的上述许多缺点。

Visor 在我们的抽象 enclave 模型内提供针对**任何利用数据依赖性访问模式的攻击信道**的保护，这代表了 enclave 上已知的一大类攻击（例如，缓存攻击 [90, 99, 12, 67, 34]）、分支预测 [54]、基于分页的攻击 [14, 111] 或内存总线窃听 [52]）。我们注意到，即使禁用了共同租用（这会带来相当大的开销），特权软件（如操作系统和虚拟机监控程序）仍然可以推断访问模式（例如，通过监控页错误），因此仍然需要数据无关（data-oblivious）的解决方案。

最近的研究显示了 GPU 上的侧信道泄漏 [45, 46, 70, 71]，包括利用 GPU 外部的数据访问模式。我们预计，随着视频和 ML 工作负载的普及，类似的攻击也会针对 GPU _enclave_ 发起，我们的威胁模型同样适用于 GPU enclave。

## 3.2 视频流与 CNN 模型

每个客户端拥有其视频流，并期望保护其视频免受云和视频分析服务的共同租户的侵害。视觉算法假定是公开的。

我们假设 CNN 模型的架构是公开的，但其权重是私有的，并且可能专属于客户端或云服务。Visor 根据 §3.1 中的威胁模型和保证，在 enclave 内保护这两种场景下的权重；但是，当权重专属于云服务时，客户端可能通过分析流水线结果来了解有关权重的一些信息 [25, 26, 99]。此类攻击不在 Visor 的考虑范围内。

最后，最近的研究表明，摄像头的加密网络流量会将视频的比特率变化泄漏给观察网络的攻击者 [88]，这可能进而泄漏有关视频内容的信息。Visor 通过在摄像头处对视频段进行填充来消除这种泄漏，这种方式优化了在云端解码填充后流的延迟（§6.1）。

## 3.3 数据无关性的可证明保证

Visor 在我们来自 §3.1 的抽象 enclave 模型内提供**数据无关性**，这保证了 enclave 代码的内存访问模式不会泄露任何有关敏感数据的信息。我们依赖 enclave 本身来提供完整性以及经过认证的加密。

我们使用“模拟范式”[27] 来阐述数据无关性的保证。首先，我们定义攻击者在我们威胁模型中看到的观察轨迹。然后，我们定义公共信息，即我们不试图隐藏且攻击者已知的信息。利用这些，我们论证存在一个模拟器，使得对于所有视频 $V$，当仅给定公共信息（关于 $V$ 和视频算法）时，**该模拟器可以产生一条与攻击者观察 Visor 处理 $V$ 期间的访问模式所看到的真实轨迹无法区分的轨迹。**“无法区分”是指没有多项式时间的攻击者能够区分模拟轨迹和攻击者观察到的真实轨迹。模拟器能够即使不知道视频流中的私有数据也能产生与攻击者所见相同的观察结果，这一事实意味着攻击者无法学习有关视频的敏感数据。

在我们的攻击者模型中，观察轨迹是对代码和数据的存储器引用地址序列，以及被访问的数据（已加密）。公共信息是 Visor 的所有算法、格式和大小信息，但不包括视频数据。为了效率，Visor 还接受一些公共参数作为输入，这些参数代表了视频流各种属性的上界，例如每帧的最大对象数，或对象尺寸的上界。

我们将 Visor 安全保证的形式化处理——包括安全性的定义和证明，以及每个算法的详细伪代码——推迟到一个扩展的附录 [79]。总之，我们表明 Visor 的数据无关算法（§6 和 §7）遵循一个完全相同的内存访问序列，该序列仅依赖于公共信息并且独立于数据内容。



# 4 隐私保护型机器学习即服务（MLaaS）框架

在本节中，我们提出一种适用于机器学习即服务（MLaaS）的隐私保护框架，该框架支持跨 CPU 和 GPU 资源的基于卷积神经网络（CNN）的机器学习应用。尽管 Visor 专注于保护视频分析流水线，但我们的框架可更广泛地应用于一系列 MLaaS 应用，如医学成像、推荐系统和财务预测等。

我们的框架包含三个关键特性，共同实现了机器学习服务的数据无感知执行。首先，它利用跨 CPU 和 GPU 资源的混合可信执行环境（TEE）保护机器学习流水线中的计算过程。其次，它提供了安全的 CPU-GPU 通信通道，进一步防止通过通道中的流量模式泄露信息。第三，它通过一组优化的原语助力开发数据无感知模块，从而防止 CPU 和 GPU 上基于访问模式的泄露。

## 4.1 混合 TEE 架构

图 3 展示了 Visor 的架构。Visor 从客户端摄像头接收加密的视频流，然后将其输入视频处理流水线。我们将该架构称为混合 TEE，因为它跨越了 CPU 和 GPU TEE，视频流水线的不同模块（第 2.1 节）分布在这些 TEE 中。先前的研究表明，将流水线的非 CNN 模块运行在 CPU 上，而将 CNN 运行在 GPU 上（[36,64,80]），能够高效利用昂贵的 GPU 资源，同时仍能跟上视频的输入帧率，我们遵循这一思路进行设计。


>[!notion]- 图3
>视窗混合TEE架构。锁表示加密数据通道，而密钥表示解密点。
>![[Pasted image 20250919200027.png]]
>
无论模块在 CPU 和 GPU 之间如何分布，正如第 3.1 节所解释的，基于数据访问模式的攻击都可能对 CPU 和 GPU TEE 发起。因此，我们的数据无感知算法和技术具有广泛的适用性，不受模块分布方式的限制，不过我们的描述基于非 CNN 模块运行在 CPU、CNN 运行在 GPU 的场景。

### CPU 和 GPU TEE

我们使用 Intel SGX 飞地实现 CPU TEE，并使用 Graviton 安全上下文实现 GPU TEE（[107]）。CPU TEE 还运行 Graviton 的可信 GPU 运行时，这使 Visor 能够安全地启动 GPU TEE，并在各个 TEE 之间建立统一的信任域。GPU 运行时与运行在 CPU TEE 外部主机上的不可信 GPU 驱动程序通信，通过 ioctl 调用管理 GPU 上的资源。在 Graviton 中，每个 ioctl 调用都被转换为提交给命令处理器的一系列命令。Graviton 通过以下方式确保命令提交（以及后续的 ioctl 传递）的安全性：（i）对于任务提交，运行时使用认证加密来保护命令不被丢弃、重放或重新排序；（ii）对于资源管理，运行时验证 GPU 在完成后返回的签名摘要。GPU 运行时对所有 TEE 间通信进行加密。

我们使用 Graphene LibOS（[100]）将非 CNN 视频模块（图 1）移植到 SGX 飞地中。在此过程中，我们对 Graphene 进行了 instrumentation，以支持运行时用于与 GPU 驱动程序通信的 ioctl 调用。

### 流水线执行

混合架构要求我们防范针对 CPU TEE、GPU TEE 以及 CPU-GPU 通道的攻击。如图 3 所示，Visor 在 CPU TEE 内解密视频流，并以无感知方式解码出每一帧（第 6 节）。然后，Visor 使用无感知视觉算法处理解码后的帧，从每一帧中提取目标（第 7 节）。Visor 从每一帧中提取相同数量、相同尺寸的目标（其中一些是虚拟目标，最多不超过上限），并将其送入循环缓冲区。这避免了泄露每一帧中实际目标的数量及其尺寸；攻击者可以观察到对缓冲区的访问，但目标本身是加密的。目标从缓冲区出队并发送到 GPU（第 4.2 节），在 GPU TEE 中被解密并由 CNN 以无感知方式处理（第 4.3 节）。

## 4.2 CPU-GPU 通信

尽管图 3 中的 CPU-GPU 通道传输的是加密目标，但 Visor 需要确保其流量模式与视频内容无关。否则，观察该通道的攻击者可以推断出目标的处理速率，进而推断出每一帧中检测到的目标数量（和尺寸）。为解决这一泄露问题，Visor 确保：（i）CPU TEE 每帧向 GPU 传输相同数量的目标；（ii）GPU TEE 中 CNN 推理以固定速率（或批大小）运行。关键在于，Visor 确保 CNN 尽可能少地处理虚拟目标。虽然我们的描述聚焦于图 1（a），以隐藏一帧中目标在 GPU 上的处理速率，但我们的技术也直接适用于图 1（b）的流水线，通过虚拟帧来隐藏完整帧的处理速率。

由于 CPU TEE 已经为实现无感知性每帧提取固定数量的目标（设为k_{max}），因此我们也强制 CNN 的推理速率为k_{max}，无论每一帧中实际目标的数量（设为 k）是多少。在实际应用中，很容易为每个视频流确定上限k_{max}。然而，这会导致 GPU 资源的浪费，因为现在 GPU 还必须对每帧中(k_{max}-k)个虚拟目标运行推理。为限制这种浪费，我们开发了一种无感知协议，以尽可能减少处理的虚拟目标数量。

### 无感知协议

Visor 每帧对$k'（<<k_{max}）$个目标运行 CNN 推理。Visor 的 CPU 流水线从每一帧中提取$k_{max}$个目标（必要时提取虚拟目标），并将其推入循环缓冲区的头部（图 3）。以固定速率（例如，每帧一次，或对于 30fps 的视频每 33 毫秒一次），从缓冲区尾部出队k'个目标并发送到 GPU，GPU 对所有k'个目标运行推理。

我们通过以下方式减少 GPU 处理的虚拟目标数量：使用 osort 对缓冲区按 “优先级” 值升序排序（虚拟目标被分配较低的优先级），从而将虚拟目标移至缓冲区头部，将实际目标移至尾部。从缓冲区尾部出队可确保实际目标优先处理，且头部的虚拟目标在被发送到 GPU 之前很可能被覆盖。循环缓冲区的大小设置得足够大，以避免实际目标被覆盖。

消费（或推理）速率$k'$应根据视频流帧中实际出现的目标数量来设置。$k'$值过高会导致因虚拟推理而浪费 GPU 资源，而值过低则会导致帧中目标的处理延迟（并可能在循环缓冲区中被覆盖）。在我们的实验中，我们使用$k' = 2×k_{avg}$（$k_{avg}$是一帧中目标的平均数量），这导致的延迟和浪费都很小。

### 带宽消耗

为实现无感知性，额外的虚拟目标导致 CPU-GPU PCIe 总线（图 3）上的流量增加，但这并不是问题，因为该总线不受带宽限制。即使使用 Visor 的无感知视频流水线，我们测得的数据速率也 < 70 MB/s，而 PCIe 互连可提供数 GB/s 的带宽。

## 4.3 GPU 上的 CNN 分类

CNN 在 GPU 上以固定速率处理尺寸相同的目标。绝大多数 CNN 操作（如矩阵乘法）本质上具有与输入无关的访问模式（[30,75]）。非无感知的操作可归类为条件赋值。例如，ReLU 函数在给定输入 x 时，将 x 替换为$max(0,x)$；同样，最大池化层将方形输入数组中的每个值替换为其最大值。

最大值运算符的无感知实现可对整数 / 浮点数使用 CUDA 的 $max/fmax$ 内在函数，这些函数会被编译为 IMNMX/FMNMX 指令（[74]），以无分支方式执行最大值操作。这确保了代码不存在依赖于数据的访问，使得 CNN 推理具有无感知性。

## 4.4 CPU 上的无感知模块

在提供了无感知的 CPU-GPU 通道和 GPU 上的 CNN 执行后，我们着手处理在 CPU 上执行的视频模块（图 1）。我们使用新颖的高效算法精心设计了视频模块的无感知版本（将在后续章节中描述）。为实现我们的算法，我们使用了一组无感知原语，总结如下。

### 无感知原语

我们使用三种基本原语，与先前的研究类似（[75,82,87]）。这些原语的基础是 x86 的 CMOV 指令，该指令接收两个寄存器（源寄存器和目标寄存器）作为输入，如果条件为真，则将源寄存器的值移动到目标寄存器。一旦操作数被加载到寄存器中，这些指令就不受基于内存访问的模式泄露的影响，因为寄存器是处理器私有的，使得任何寄存器到寄存器的操作默认都是无感知的。

1. 无感知赋值（oassign）：oassign 原语是 CMOV 指令的包装器，可根据条件将值赋给目标操作数。通过简单地将输入条件设置为 false，该原语可用于执行虚拟写入操作。我们为不同的整数大小实现了该原语的多个版本。我们还使用 SIMD 指令实现了向量化版本。
2. 无感知排序（osort）：osort 原语借助双调排序网络（[6]）以无感知方式对数组进行排序。给定一个大小为 n 的输入数组，该网络通过执行$O(n log^2(n))$次比较 - 交换操作来对数组排序，这些操作可使用 oassign 原语实现。由于给定输入大小 n 后网络布局是固定的，因此每个网络的执行都具有相同的内存访问模式。
3. 无感知数组访问（oaccess）：oaccess 原语访问数组中的第 i 个元素，而不泄露 i 的值。实现 oaccess 的最简单方法是扫描整个数组。然而，正如我们的威胁模型（第 3.1 节）所讨论的，超线程被禁用，这防止了与攻击者共享核心内资源（如 L1 缓存），从而减轻了已知的利用共享核心内资源泄露缓存行级以下粒度访问模式的攻击（[68,113]）。因此，我们假设访问模式泄露的粒度为缓存行，对于无感知性而言，oaccess 只需以缓存行粒度扫描数组即可，无需以元素或字节为粒度。

# 5 设计无感知视觉模块

用于视觉模块无感知执行的朴素方法和通用工具可能会导致极高的性能开销。例如，为图 1 中的 CPU 视频分析模块实现无感知版本的朴素方法，就是简单地使用第 4.4 节中概述的无感知原语重写它们。这种方法：（i）消除所有分支，并将条件语句替换为 oassign 操作，以防止通过代码访问模式泄露控制流；（ii）通过 oaccess 实现所有数组访问，以防止通过数据内存访问泄露信息；（iii）固定迭代次数，必要时执行虚拟操作。然而，这种方法的简单性是以高昂的开销为代价的：会导致性能下降两到三个数量级。此外，正如我们在第 8.3 节中所展示的，用于无感知程序执行的通用工具（如 Raccoon [82] 和 Obfuscuro [1]）也存在巨大的开销 —— 性能下降六到七个数量级。

相反，我们证明，通过使用第 4.4 节中概述的原语精心设计无感知视觉模块，Visor 的性能比朴素方法高出多个数量级。在本节的剩余部分，我们将概述我们的设计策略，然后在第 6 节和第 7 节中深入探讨算法的详细设计。

## 5.1 设计策略

我们的核心目标是将每种算法转换为一种模式，即无论像素值如何，都对每个像素执行相同的处理。为了高效地应用这种设计模式，我们基于视觉模块的特性，设计了一套算法和系统优化策略，具体如下。

1. 分治法提升性能：我们根据功能将每个视觉算法分解为独立的子例程，并分别使每个子例程实现无感知性。直观地说，该策略通过以下两点提升性能：（i）允许我们为每个子例程单独定制优化；（ii）避免无感知性的开销被叠加放大。
2. 基于扫描的顺序处理：图像的无感知处理要求图像中的每个像素都无法与其他像素区分。这一要求为重新设计顺序图像处理算法提供了契机。我们发现，与其简单地使用第 4.4 节中的数据无感知原语重写现有算法，不如将算法重新设计为扫描图像的形式，同时对每个像素应用相同的功能，这样能获得更优的性能。直观地讲，这是因为任何非顺序的像素访问都隐含着需要为实现无感知性而扫描整个图像（例如，使用 oaccess）；因此，通过将算法转换为基于扫描的算法，我们可以消除此类非顺序访问。
3. 跨像素组分摊成本：以相同方式处理每个像素，自然适用于支持对像素进行批量计算的优化策略 —— 例如，使用数据并行（SIMD）指令。

在 Visor 中，我们遵循上述通用策略，设计了可组合且可在不同流水线中复用的主流视觉模块的无感知版本。然而，我们的策略也可能为除我们所考虑的模块之外的其他无感知视觉模块的设计提供参考。

## 5.2 无感知算法的输入参数

我们的无感知算法依赖于一组公共输入参数，这些参数需要在部署视频流水线之前提供给 Visor。这些参数代表了视频流属性的各种上限，例如每帧的最大目标数量或每个目标的最大尺寸。图 4 总结了视觉流水线所有模块的输入参数列表。

确定这些参数有多种方法。（i）模型所有者可以在使用公共数据集训练模型的同时获取这些参数。（ii）客户端可以对其视频流进行离线实证分析，并选择一组合适的参数。（iii）Visor 也可以增强为基于历史数据动态计算这些参数（尽管我们未实现此功能）。我们注意到，提供这些参数并非绝对必要，但合理的参数可以显著提升我们算法的性能。

# 6 无感知视频解码

视频编码将一系列原始图像（称为帧）转换为压缩的比特流。帧分为两种类型：关键帧和间帧。关键帧的编码仅利用同一帧内像素间的冗余。另一方面，间帧以先前的帧（或最近的关键帧）作为参考，因此可以利用帧间像素的时间冗余。

## 编码概述

我们以 VP8 编码器 [5] 为基础展开讨论，但我们的技术具有广泛的适用性。一帧会被分解为称为块的方形像素数组，然后通过以下步骤进行压缩（见图 5）。

首先使用参考像素（如果是间帧则来自前一帧，如果是关键帧则来自当前帧）预测块的估计值。然后从实际块中减去该预测值以获得残差。每个残差块会被转换到频域（例如，使用离散余弦变换），其系数会被量化以提升压缩效果。每个（量化后的）块通过二进制前缀树和算术编码被压缩为可变长度的比特流。块预测模式、余弦变换和算术编码是所有视频编码器（例如 H264 [33]、VP9 [108]）的核心，因此我们的无感知技术可推广到所有主流编解码器。

解码器逆转编码器的步骤：（i）对输入的视频比特流进行熵解码（第 6.2 节）；（ii）对得到的系数进行反量化和逆变换以获得残差块（第 6.3 节）；（iii）使用先前解码的像素作为参考得到预测块，然后将其与残差相加（第 6.4 节）。此处的解释经过了简化；详细的伪代码以及安全性证明请参见扩展附录 [79]。

## 6.1 视频编码器填充

当视频流在传输过程中，即使流量经过 TLS 加密，观察网络的攻击者也能看到每一帧的比特率变化。这种可变性可被用于对视频流进行指纹识别 [88] 并了解其内容。要克服这种泄露，需要修改视频编码器，在将流发送到 Visor 之前，用虚拟比特将每一帧填充到上限。

我们修改了视频编码器以对编码后的视频流进行填充。但我们不是在帧级别进行填充，而是对帧内的每个块行进行填充。与帧级填充相比，对单个块行进行填充可显著降低无感知解码的延迟，但代价是网络带宽增加。

然而，对视频流的帧进行填充会抵消编码原始视频流时间帧间的优势 —— 间帧通常比关键帧小得多。因此，我们将编码器配置为将所有原始视频帧编码为关键帧，这消除了处理间帧的额外复杂性，从而简化了无感知解码过程。

我们注意到，可能无法修改 legacy 摄像头以纳入填充功能。在这种情况下，可行的解决方案包括部署轻量级边缘计算设备，在将摄像头输入流传输到云端之前对其进行填充。为完整起见，我们还在附录 A 中讨论了不进行填充的影响，以及随之而来的安全性 - 性能权衡。

## 6.2 比特流解码

比特流解码器借助前缀树重建块。在树的每个节点，它通过算术解码从压缩比特流中解码出单个比特，并根据比特值遍历树。解码比特时，解码器首先检查当前比特流位置是否还有更多可解码的比特，如果没有，则将比特流指针向前推进两个字节。到达叶节点后，它会根据叶节点的位置输出一个系数，并将该系数分配给块中的当前像素。此过程会针对帧中的所有系数重复进行。

### 无感知性要求

上述算法会泄露有关压缩比特流的信息。首先，树的遍历会泄露解析出的系数值。为实现无感知性，我们需要确保在遍历过程中，当前正在处理的节点身份保持保密。其次，比特流中并非每个位置都编码相同数量的系数，并且解码过程中比特流指针的推进是可变的。因此，这会泄露每两个字节块中编码的系数数量（这可能会传递其值）。我们设计了一种解决方案，将系数的解析（即前缀树遍历，第 6.2.1 节）与解析出的系数分配给像素的过程（第 6.2.2 节）分离开来。

#### 6.2.1 无感知前缀树遍历

使树遍历实现无感知性的一种简单方法是将前缀树表示为数组。然后，我们可以使用 oaccess（第 4.4 节）无感知地获取树中的任何节点。虽然这隐藏了所获取节点的身份，但我们还需要确保对节点的处理不会泄露其身份。

具体而言，我们需要确保通过在每个节点执行相同的操作集，使节点之间无法区分。遗憾的是，以下事实使这一要求变得复杂：（1）只有树中的叶节点会产生输出（即解析出的系数），中间节点不会；（2）我们事先不知道树中的哪些节点会导致比特流指针推进；同时，我们需要确保指针的推进是可预测的且与比特流无关。为解决这些问题，我们采取以下步骤：

1. 我们修改每个节点，使其无论处于叶节点状态还是其他状态，都输出一个系数。叶节点输出解析出的系数，其他状态输出虚拟值。
2. 我们在前缀树中引入一个虚拟节点。在遍历树的过程中，如果当前比特流位置没有更多可解码的比特，我们就转换到虚拟节点并执行有限次数的虚拟解码。

这些修改确保了在遍历前缀树时，攻击者所能看到的只是：在树中的某个节点，解码了一个比特并输出了一个值。

请注意，在这一阶段，我们不会将系数分配给像素，而是将它们收集在一个列表中。如果我们在此阶段将系数分配给像素，那么解码器需要在树的每个节点处无感知地扫描整个帧（使用 oaccess），以隐藏像素的身份。相反，通过将解析与分配分离，我们能够以超线性数量的访问（而非二次方）来无感知地执行分配，如下文所述。

#### 6.2.2 无感知系数分配

在第 6.2.1 节结束时，我们得到了一个包含实际系数和虚拟系数的列表。核心思想是，如果我们能够使用 osort 对这组值进行无感知排序，使所有实际系数连续排列，同时将所有虚拟系数推到前面，那么我们就可以简单地从列表的末尾按顺序读取系数，并将它们逐个分配给像素。

为了实现这种排序，我们修改前缀树遍历过程，为每个系数额外输出一个元组（flag，index）；其中 flag 对于虚拟系数为 0，对于实际系数为 1；index 是根据像素索引递增的计数器。然后，通过根据元组的值对列表进行排序，即可实现所需的排序效果。

由于无感知排序的复杂度与被排序元素的数量呈超线性关系，一项重要的优化是在块行粒度而非帧粒度上对系数进行解码和分配。虽然每个块行的比特数可能会被观察到，但由于视频流中的每个块行都被填充到了一个上限（第 6.1 节），因此算法的无感知性不会受到影响；如果我们采用帧级填充，这种优化就会泄露每个块行的比特数。在第 8.1.1 节中，我们表明这种技术将无感知解码延迟降低了约 6 倍。

## 6.3 反量化和逆变换

解码过程的下一步是：（i）对比特流中解码出的系数进行反量化，然后（ii）进行逆变换以获得残差块。反量化只需将每个系数乘以一个量化因子。逆变换也会执行一组相同的算术运算，与系数值无关。

## 6.4 块预测

预测是解码的最后阶段。将第 6.3 节中获得的残差块与使用先前构建的块作为参考得到的预测块相加，即可获得原始像素值。在关键帧中，每个块都是帧内预测的 —— 即使用同一帧中的块作为参考。我们不讨论间帧，因为如第 6.1 节所述，Visor 中经过填充的输入视频流只包含关键帧。

帧内预测块是通过多种模式之一计算的。编码块的模式指的是其顶行和左列上用作参考的像素组合。无感知性要求预测模式保持私密。否则，攻击者可以识别出彼此最相似的像素，从而泄露帧的细节。

我们通过为像素评估所有可能的预测值并将它们存储在一个数组中（按模式为每个预测值编制索引），来使帧内预测实现无感知性。然后，我们使用 oaccess 从数组中无感知地选择正确的预测值。

# 7 无感知图像处理

如第 6 节所述，在对帧进行无感知解码后，如图 1 所示，下一步是为背景减除（7.1 节）、边界框检测（7.2 节）、目标裁剪（7.3 节）和目标跟踪（7.4 节）开发数据无感知技术。我们在此呈现核心思想；详细的伪代码和无感知性证明可参见扩展附录 [79]。需要注意的是，7.1 节和 7.4 节通过修改现有主流算法使其实现无感知性，而 7.2 节和 7.3 节提出了新的无感知算法。

## 7.1 背景减除

背景减除的目标是检测视频中的运动目标。具体而言，它会动态学习属于视频背景的静止像素，然后从每一帧中减去这些像素，从而生成一幅背景像素为黑色、前景像素为白色的二值图像。

Zivkovic 等人提出了一种在实际部署中被广泛使用的机制 [116, 117]，该机制将每个像素建模为高斯混合模型 [9]。每个像素的高斯分量数量 M 因像素值而异（但不超过预先定义的常数$M_{max}$）。随着新帧等更多数据的到来，该算法会更新每个高斯分量及其权重$\pi$，并在必要时添加新的分量。

为判断像素$\vec{x}$是否属于背景，该算法会使用权重最大的 B 个高斯分量，若$p(\vec{x})$大于阈值，则判定为背景：

$p(\vec{x})=\sum_{m=1}^{B} \pi_{m} \mathcal{N}\left(\vec{x} | \vec{\mu}_{m}, \sum_{m}\right)$

其中$\vec{\mu}_{m}$和 $sum_{m}$ 是高斯分量的参数，$\pi_{m}$是第 $m$ 个高斯分量的权重。

该算法不具备无感知性，因为它为每个像素维护的高斯分量数量不同，因此在更新每个像素的混合模型时执行的步骤也不同。这些差异可通过访问模式被观察到，而这种泄露会向攻击者揭示某个像素相对于其他像素的复杂程度 —— 即该像素值是长期稳定还是频繁变化。这使得攻击者能够识别视频中运动目标的位置。

为实现无感知性，我们需要对每个像素执行相同的操作集（无论其值如何）；因此，我们始终为每个像素维护M_{max}个高斯分量，其中$(M_{max}-M)$个是虚拟分量，并被分配权重$\pi=0$。当新帧到来时，我们使用 oassign 操作对混合模型进行所有更新，对虚拟分量执行虚拟操作。同样，为了按权重选择最大的 B 个分量，我们使用 osort 原语。

## 7.2 边界框检测

7.1 节的输出是一幅二值图像，其中背景像素为黑色，前景目标表现为白色 blob（图 6 (a)）。要找到这些目标，只需找到所有 blob 的边缘轮廓，再利用这些轮廓计算每个目标的边界矩形框。在二值图像中寻找轮廓的标准方法是 Suzuki 和 Abe 提出的边缘跟踪算法 [95]。顾名思义，该算法通过扫描图像找到边缘像素，然后沿着边缘围绕 blob 追踪。正如第 2.3 节的图 2 所展示的，该算法的内存访问模式会泄露帧中所有目标的细节。

使该算法实现无感知性的朴素方法是使用 oaccess 原语实现每个像素访问（以及其他微小修改）。然而，我们的测量表明，这种方法会使算法速度减慢约 1200 倍。

我们通过改进经典的连通分量标记（CCL）技术 [85]，设计了一种双遍无感知算法来计算边界框。该算法的主要步骤如图 6 (a) 所示（其原始二值图像包含两个 blob）。在第一遍扫描中，它会扫描图像，为每个与其他像素 “连通” 的像素分配一个临时标签。在第二遍扫描中，它会合并属于同一目标的标签。尽管连通分量标记本身在 blob 检测效率上不如边缘跟踪，但它更易于适配以实现无感知性。

>[!notion]- 图6 无意识边界框检测
>![[Pasted image 20250919203548.png]]

我们通过以下方式使该算法实现无感知性：首先，无论当前像素是否与其他像素连通，都执行相同的操作；其次，为提高效率，我们将第一遍扫描中临时标签的最大数量限制为 Visor 的输入参数 N（参见 5.2 节，图 4）。需要注意的是，该参数值可能远低于最坏情况下的上限（即像素总数），因此效率更高。

### 并行化优化

我们发现，可通过分治法对该无感知算法进行并行化处理。我们将帧划分为水平条带（如图 6 (b) 所示），并并行处理每个条带。

对于跨条带边界的目标，每个条带仅输出包含条带内像素的部分边界框。我们通过对相邻条带的边界重新应用无感知连通分量标记算法，来合并这些部分边界框。

对于上下相邻的两个条带$S_{i}$和$S_{i+1}$，我们将$S_{i+1}$顶行的每个像素与其在$S_{i}$底行的相邻像素进行比较，并根据需要合并它们的标签。

## 7.3 目标裁剪

检测到目标的边界框后，下一步是将其从帧中裁剪出来，以发送至 CNN 进行分类（图 1 (a)）。Visor 需要确保目标裁剪过程不会泄露：（i）目标的位置；（ii）目标的尺寸。

### 7.3.1 隐藏目标位置

对尺寸为p×q的目标进行无感知裁剪的朴素方法是：按光栅顺序水平滑动一个尺寸为p×q的窗口，若窗口与目标的边界框对齐，则复制窗口内的像素；否则，执行虚拟复制。然而，这种方法会导致速度减慢 4000 倍，主要原因是存在冗余复制：当窗口向前滑动一个像素到达帧中的新位置时，复制的大多数像素与前一位置的像素相同。

我们通过将算法分解为多个步骤（沿图像的每个维度执行一个步骤）来消除这种冗余，使得每个步骤仅执行一部分工作。如图 7 (a) 所示，第一阶段提取包含目标的水平条带；第二阶段从水平条带中提取目标。

我们不使用尺寸为p×q的窗口在尺寸为m×n的帧上滑动，而是使用一个尺寸为m×q的水平条带 —— 其宽度 m 与帧的宽度相同，高度 q 与目标的高度相同。我们将该条带逐行垂直向下滑动帧。若条带的上下边缘与目标对齐，则将条带覆盖的所有像素复制到缓冲区；否则，执行虚拟复制。

我们分配一个尺寸与目标相同的p×q窗口，然后在提取的条带上逐列滑动该窗口。若窗口的左右边缘与目标的边界框对齐，则将窗口内的像素复制到缓冲区；否则，执行虚拟复制。

### 7.3.2 隐藏目标尺寸

7.3.1 节中的算法会泄露目标的尺寸p×q。为隐藏目标尺寸，Visor 接收表示目标尺寸上限的输入参数 P 和 Q（如 5.2 节图 4 所述），而非裁剪出尺寸恰好为p×q的目标，我们会无感知地裁剪出一个尺寸为P×Q、包含该目标的更大图像。尽管目标尺寸会因其在帧中的位置（例如，靠近或远离摄像头）而变化，但最大值（P 和 Q）可通过对几分钟的视频样本进行分析来获取，且在我们的数据集中这些值往往保持不变。

这个更大的图像现在包含了目标周围的多余像素，这可能会导致 CNN 在目标分类时出错。我们通过无感知地将p×q的目标放大以填充P×Q的缓冲区，来移除目标周围的多余像素。需要注意的是，我们通过 CPU-GPU 通道发送给 CNN 的所有目标均为P×Q尺寸（4.2 节），且如 4.1 节所述，我们从每一帧中提取相同数量的目标（必要时填充虚拟目标）。

我们开发了一种使用双线性插值 [40] 进行放大的无感知例程。双线性插值通过对原始图像中 2×2 像素数组的线性组合来计算放大图像中的像素值（见图 7 (b)）。我们再次通过将算法分解为两个步骤来提高效率（图 7 (c)），每个步骤仅沿一个维度执行放大操作。

### 缓存局部性

由于（分解后的双线性插值）算法的第二步骤执行列向插值，插值过程中的每个像素访问都会触及不同的缓存行。为利用缓存局部性，我们在第二步骤之前对图像进行转置，使第二步骤也能像第一步骤一样执行行向插值。这使得速度又提升了一个数量级（8.1.4 节）。

## 7.4 目标跟踪

目标跟踪包含两个主要步骤：每一帧中的特征检测和帧间的特征匹配。

### 特征检测

SIFT [57,58] 是一种用于提取关键点（即帧中最 “有价值” 的像素）特征的主流算法。简而言之，它会生成候选关键点（每个候选都是局部极大值 / 极小值），然后对候选关键点进行筛选以获得合法的关键点。

根据 SIFT 算法的访问模式，攻击者可以推断出图像中所有关键点的位置，进而揭示图像中所有目标 “角点” 的位置。使该算法实现无感知性的朴素方法是将每个像素都视为关键点，并对每个像素执行上述所有操作。然而，SIFT 算法的性能在很大程度上依赖于其从帧中筛选出少量优质关键点的能力。

为实现无感知性和高效性，Visor 接收两个参数N_{temp}和 N 作为输入（见图 4）。参数$N_{temp}$表示候选关键点数量的上限，N 表示合法关键点数量的上限。这些参数与 oassign 和 osort 相结合，使得能够高效且无感知地识别关键点。最后，计算每个关键点的特征描述符需要访问其周围的像素，为此我们使用无感知提取技术（7.3 节）。

### 特征匹配

特征检测后的下一步是在图像间进行特征匹配。特征匹配计算两组特征之间的距离度量，并识别两组中 “最接近” 的特征。在 Visor 中，我们使用 oassign 操作选择最接近的特征，对两组特征执行暴力匹配。

# 8 评估

## 实现

我们在 FFmpeg 的 VP8 解码器 [24] 基础上实现了无感知视频解码器，在 OpenCV 3.2.0 [77] 基础上实现了无感知视觉算法。我们使用 Caffe [43] 运行卷积神经网络（CNNs）。我们采用 AES-GCM 对数据通道进行加密。我们使用内联汇编代码实现了第 4.4 节中的无感知原语（与 [75,82,87] 一致），并手动验证了二进制文件，以确保编译器优化不会破坏我们的设计意图；也可以使用 Vale [7] 等工具进行此项验证。

## 测试平台

我们在 Intel i7-8700K 处理器（6 核，主频 3.7 GHz）和 NVIDIA GTX 780 GPU（2304 个 CUDA 核心，主频 863 MHz）上对 Visor 进行评估。在 Visor 的实验中，我们禁用了超线程（详见第 3 节），但在非安全基线中保留了超线程。出于安全性考虑禁用超线程并不会牺牲 Visor 的性能（因其无感知算法大量利用向量单元），而基线系统则更依赖超线程；更多细节参见附录 B。服务器运行 Linux v4.11 系统，支持 AVX2 和 SGX-v1 指令集，配备 32 GB 内存（其中飞地内存为 93.5 MB）。GPU 配备 3 GB 内存。

## 数据集

我们在实验中使用了四个真实世界的视频流（已获得使用许可）：流 1 和流 4 来自贝尔维尤市的交通摄像头（分辨率 1280×720），流 2 和流 3 来自监控商业数据中心的摄像头（分辨率 1024×768）。所有这些视频都具有隐私敏感性，涉及政府法规或商业机密。为了评估不同分辨率和比特率下无感知性的开销，我们对视频进行了相应的重新编码。近期的研究 [44,48,115] 发现，降低分辨率不会影响视频流中目标检测的准确性（同时会显著减少资源消耗），且 720p 视频已能满足需求。因此，我们选择使用分辨率接近 720p 的视频流，因为我们认为它们能更准确地反映实际性能。

## 评估要点

我们总结了评估的核心结论：

1. Visor 的优化无感知算法（第 6 节、第 7 节）比朴素的竞争方案快高达 1000 倍。（第 8.1 节）
2. 对于采用最先进 CNN 的真实世界视频流水线，无感知性的端到端开销相对于非无感知基线仅为 2 倍–6 倍。（第 8.2 节）
3. Visor 具有通用性，能够适配结合不同视觉处理算法和 CNN 的多种流水线（第 2.1 节；图 1）。（第 8.2 节）
4. 与最先进的通用无感知程序执行系统相比，Visor 的性能快超过 6 到 7 个数量级。（第 8.3 节）

总体而言，Visor 对视频流属性的利用不会对分析结果的准确性产生任何影响。

## 8.1 无感知组件的性能

我们首先研究 Visor 无感知模块的性能：量化我们的算法（不含飞地）相对于非无感知基线的原始开销；同时测量相对于朴素无感知方案的性能提升。

### 8.1.1 无感知视频解码

压缩比特流的解码主导了解码延迟，占总延迟的比例高达约 90%。此外，该阶段的开销主要来自无感知分配子程序 —— 它使用 osort 将系数排序到正确的像素位置，占解码延迟的比例高达约 83%。由于无感知排序的复杂度与被排序元素的数量呈超线性关系，我们采用的按块行而非按帧进行解码的技术，显著降低了无感知解码的延迟。

#### 开销

图 8 展示了不同无感知解码策略（即按帧解码或按块行解码）下，分辨率为 1280×720 的视频流的带宽使用情况和解码延迟。我们还纳入了两个参考基准：未编码帧和 VP8 编码帧。VP8 编码帧的基线解码延迟为 4–5 毫秒。未编码的原始帧没有解码延迟，但在 4 Mb/s 比特率下，其帧大小比 VP8 的平均帧大小（数十 kB）大三个数量级。

按帧进行无感知解码会导致极高的延迟（约 850 毫秒），比非无感知方案高两个数量级。此外，为防止泄露帧的比特率而对每个帧进行填充，会使平均帧大小增加到约 95 kB。相反，按块行进行无感知解码的延迟约为 140 毫秒，比按帧解码低约 6 倍。但这需要付出一定的网络带宽代价 —— 编码器需要对每个块行单独进行填充，而非对一帧进行填充。具体而言，帧大小从约 95 kB 增加到约 140 kB。

除了解码粒度外，无感知排序的延迟还受以下两个因素影响：（i）帧的分辨率；（ii）比特率。帧的分辨率 / 比特率越高，需要排序的系数就越多。图 9 展示了在不同分辨率和比特率的视频流中，按块行粒度进行无感知解码的延迟。该图表明，分辨率 / 比特率越低，解码开销越小。在许多情况下，较低的图像质量足以满足视频分析需求，因为它不会影响目标分类的准确性 [44]。

### 8.1.2 背景减除

遵循先前的研究 [116,117]，我们将每个像素的最大高斯分量数量\(M_{max}\)设置为 4。我们为实现无感知性所做的修改，使我们能够利用 SIMD 指令并行更新高斯分量。这是因为我们现在为每个像素维护相同数量的分量，且每个分量的更新操作是相同的。

图 10 展示了不同分辨率下，无感知性对背景减除的开销影响。SIMD 实现的例程延迟仅比非无感知基线例程高 1.8 倍。由于该例程独立处理帧中的每个像素，其延迟随像素总数线性增加。

### 8.1.3 边界框检测

对于非无感知边界框检测，我们使用 Suzuki 和 Abe 提出的边缘跟踪算法 [95]（详见第 7.2 节）；该算法效率很高，延迟仅为亚毫秒级。

我们的无感知边界框检测算法的性能受两个参数影响：（i）分治法中使用的条带数量（控制并行度）；（ii）每个条带允许的最大标签数量上限 L（决定算法数据结构的大小）。

图 11 展示了不同帧分辨率下，随着帧被划分的条带数量变化，参数 L 的取值情况。正如预期的那样，条带数量越多，每个条带所需的 L 值就越小。同样，分辨率越低的帧需要的 L 值也越小。

图 12 展示了基于参数 L 的值，检测一帧中所有边界框的延迟，范围从几毫秒到几百毫秒。对于给定的分辨率，随着条带数量的增加，延迟会降低，原因有二：（i）并行度提高；（ii）每个条带所需的 L 值减小。总体而言，分治法将延迟降低了一个数量级，降至几毫秒。

### 8.1.4 目标裁剪

我们首先评估泄露目标尺寸时的无感知目标裁剪性能。我们纳入了三种方案：朴素方法、两阶段方法，以及进一步优化的多行列滑动窗口方法。图 13 展示了从 1280×720 帧中裁剪不同尺寸目标的开销，结果表明所提出的优化方案将延迟降低了三个数量级。

图 14 展示了为隐藏目标尺寸而对裁剪图像中的目标 ROI 进行无感知缩放的延迟。对于大型目标，朴素双线性插值的延迟很高（数十毫秒），而优化的两阶段方法（通过在第二阶段前对图像进行转置以利用缓存局部性；第 7.3.2 节）将延迟降低了两个数量级，对于大型目标也仅需 1 毫秒。

### 8.1.5 目标跟踪

图 15 展示了有无无感知性的目标跟踪延迟。我们检查了不同分辨率下的样本流，以确定帧中特征数量的上限。随着分辨率的提高，无感知性的开销也会增加，因为我们的算法需要对检测到的中间特征集进行无感知排序，其成本与集合大小呈超线性关系。总体而言，开销小于 2 倍。

### 8.1.6 GPU 上的 CNN 分类

#### 缓冲区
图 17 基准测试了排序成本与目标大小和缓冲区大小的关系。当缓冲区大小小于 50 时，排序成本保持在 5 毫秒以下。

#### 推理
我们测量了 GPU 上 CNN 目标分类的性能。如第 4.3 节所述，无感知推理无需额外成本。图 16 列出了使用专有 NVIDIA 驱动程序（CUDA 9.2 版本）时不同 CNN 模型的吞吐量。每个模型接收 10 个 224×224 大小的目标作为一批输入。此外，由于 GPU 内存限制为 3 GB，我们还列出了测试平台上可运行的最大并发模型数量。正如我们在第 8.2 节中所展示的，后者直接影响可并发服务的视频分析流水线数量。

## 8.2 系统性能

我们现在使用四个真实视频流评估视频分析流水线的端到端性能。我们展示了运行 Visor 的数据无感知技术并将流水线部署在混合飞地中的开销。我们评估了图 1 中的两个示例流水线：流水线 1 使用目标分类 CNN；流水线 2 使用目标检测 CNN（Yolo），并在 CPU 上执行目标跟踪。

### 流水线 1 配置

我们对尺寸大于帧大小 1% 的目标进行推理，因为较小的检测目标没有实际意义。在我们的视频中，每帧此类目标的数量很少 —— 没有帧包含超过 5 个目标，且 97%–99% 的帧包含的目标少于 2 到 3 个。因此，我们进行如下配置：（i）Visor 的目标检测阶段保守地每帧向缓冲区输出 5 个目标（包括虚拟目标）；（ii）Visor 的 CNN 模块的消费速率为每帧 2 或 3 个目标（取决于视频流）；（iii）缓冲区大小设置为 50，足以防止非虚拟目标被覆盖。

### 流水线 2 配置

Yolo 目标检测 CNN 接收完整帧作为输入，而非单个目标。在基线中，我们通过背景减除过滤不包含任何目标的帧。但在无感知版本中，由于我们的样本流中大多数帧都包含前景目标，我们放弃了这种过滤。此外，Yolo 要求输入帧的分辨率为 448×448。因此，我们将输入视频流调整为相同的分辨率。

### 无感知性成本

图 18 和图 19 展示了在并发流水线数量变化时，Visor 对流水线 1 和流水线 2 的 CPU 端组件的开销影响。与非无感知基线相比，Visor 使两个流水线的峰值 CPU 吞吐量降低了约 2.6 倍–6 倍。然而，系统的吞吐量最终取决于可装入 GPU 内存的模型数量。

图 20 展示了两个流水线在所有四个样本视频流中的端到端性能。在存在 CNN 推理的情况下，Visor 的开销取决于模型复杂度。使用轻量级模型（如 AlexNet 和 ResNet-18）的流水线受 CPU 瓶颈限制。在这种情况下，开销由 CPU 组件产生的无感知性成本决定。使用重量级模型（如 ResNet-50 和 VGG）时，性能瓶颈转移到 GPU。在这种情况下，Visor 的开销由 GPU 处理的虚拟目标数量决定（如第 4.2 节所述）。总体而言，对于第一个流水线，所有视频流的无感知性成本在 2.2 倍–5.9 倍范围内。在第二个流水线中，开销约为 2 倍。GPU 仅能容纳一个 Yolo 模型。然而，由于目标跟踪例程成本相对较高，系统的整体性能受 CPU 瓶颈限制。

### 飞地成本

我们通过将 NVIDIA 栈替换为 Graviton 栈（包括开源 CUDA 运行时（Gdev [50]）和 GPU 驱动程序（Nouveau [73]）），测量了在 CPU/GPU 飞地中运行流水线的成本。

图 21 比较了 Visor 与非无感知基线在均部署于 CPU/GPU 飞地时的性能。由于 SGX 的 EPC 大小限制为 93.5 MB，内存占用较大的工作负载会产生高昂的开销。对于流水线 1，在帧分辨率较大的情况下，背景减除的延迟从约 6 毫秒增加到 225 毫秒，因为其工作集大小为 132 MB。在 Visor 中，流水线的净延迟增加了 2.4 倍（由于 SGX 开销掩盖了部分 Visor 开销），同时内存占用增加到 190 MB。当流水线处理的帧分辨率较低（其内存占用可装入当前 EPC）时，非无感知基线的延迟与非安全基线的延迟相当（几毫秒）；无感知性的额外开销为 2.3 倍。

对于流水线 2，有限的 EPC 使目标跟踪的延迟从约 90 毫秒增加到约 240 毫秒。启用 Visor 的无感知性后，净延迟增加了 1.7 倍。

## 8.3 与现有工作的对比

我们通过将 Visor 与最先进的通用无感知程序执行系统 Obfuscuro [1] 进行对比，完成评估。

Obfuscuro 的当前实现支持的指令集有限，因此无法运行完整的视频分析流水线。鉴于此，我们将 OpenCV 目标裁剪模块移植到 Obfuscuro 中（该模块仅需简单的赋值操作）。在 Obfuscuro 中，从 1280×720 图像中裁剪 128×128 和 16×16 大小的目标分别需要 8.5 小时和 8 分钟，而在 Visor 中分别仅需 800 微秒和 200 微秒；这使得 Visor 的速度快超过 6 到 7 个数量级。不过，需要注意的是，Obfuscuro 追求的安全性保证比 Visor 更强（它还旨在对程序进行混淆）；因此，这并非严格意义上的直接对比。

尽管如此，巨大的性能差距难以弥合，我们的实验证明了 Visor 定制化解决方案的优势。

其他用于自动合成或执行无感知程序的工具要么是闭源的 [82,110]，要么需要专用硬件 [55,59,72]，要么需要自定义语言支持 [16]。然而，我们注意到，Raccoon [82]（提供与 Visor 相当的安全级别）的作者报告称，其在简单程序上的开销高达 1000 倍；对于视频分析等复杂程序，开销可能会更高。

# 9 讨论

## 针对上限的攻击

为提高效率，Visor 会根据用户指定的上限从每帧中提取固定数量的目标。但这使得 Visor 容易受到对抗性输入的攻击：知道该上限的攻击者可通过在帧中同时放置大量目标来干扰分析流水线。

为缓解此类攻击，我们提出两种潜在策略：（i）对于包含≥N 个目标的帧（如第 7.2 节所述检测），使用最坏情况边界（例如像素总数）在关键路径外处理这些帧。尽管这种方法会泄露哪些特定帧包含≥N 个目标，但考虑到这些帧本身具有可疑性，这种泄露可能是可接受的。（ii）根据目标大小或位置等属性过滤目标：例如，对于交通监控流，仅选择交通路口中心的目标。这限制了每帧中可能存在的有效目标数量，提高了发起此类攻击的难度。也可对流水线结果应用更复杂的过滤，并重新处理包含可疑内容的帧。

## 原生无感知编码

除了为现有编解码器设计无感知版本外，还可能构建一种 “原生无感知” 的编码方案，该方案（i）可能更简单，（ii）性能优于 Visor 的无感知解码。这一替代设计方向是未来研究的有趣课题。但我们注意到，任何此类编解码器都需要产生完全恒定的每帧比特率（CBR），以防止网络上的比特率泄露。尽管视频领域已对 CBR 编解码器进行了研究，但它们相较于 VP8 等可变比特率（VBR）方案存在劣势 —— 压缩损失更大。换言之，为达到与 VP8 相当的视频质量，原生无感知 CBR 方案将消耗比 VP8（含填充）更多的带宽，尽管其实现可能更简单。在 Visor 中，我们优先优化视频质量。

# 10 相关工作

据我们所知，Visor 是首个支持视觉流水线安全执行的系统。我们将讨论与 Visor 各方面相关的现有工作。

## 视频处理系统

已有大量研究提出优化方案以提高视频分析流水线的效率 [36,44,48,115]。这些系统提供了不同的设计方案，以实现性能与准确性之间的权衡。它们的技术与 Visor 互补，Visor 可借助其性能优化获益。

## 数据无感知技术

Eppstein 等人 [22] 开发了用于几何计算的数据无感知算法。Ohrimenko 等人 [75] 提出了在 CPU TEE 中运行的数据无感知机器学习算法。这些工作与 Visor 的设计思路相似，但不适用于我们的场景。

无感知 RAM（Oblivious RAM）[28] 是一种消除访问模式泄露的通用加密方案。尽管近期的研究已降低了其计算开销 [94]，但与定制化方案相比，其成本仍高出多个数量级。Oblix [66] 和 Zerotrace [87] 为运行在硬件飞地中的应用提供 ORAM 支持，但也存在类似的局限性。

多种系统 [1,16,55,59,72,82,93,110] 还借助 ORAM、专用硬件或基于编译器的技术，在不同层级提供隐藏访问模式的通用解决方案。但通用解决方案的效率低于 Visor 等定制化方案 —— 定制化方案可利用算法模式实现更高效率。

## TEE 的侧信道防御

Visor 为防范利用飞地中访问模式泄露的攻击提供了系统性保护。支持数据无感知执行的系统（如 Obfuscuro [1] 和 Raccoon [82]）为通用工作负载提供了相当级别的安全性，而 Visor 则专为视觉流水线定制。

此外，已有多种防御方案被提出用于检测 [19] 或缓解特定类型的访问模式泄露。例如，Cloak [31]、Varys [76] 和 Hyperrace [18] 针对缓存攻击；T-SGX [91] 和 Shinde 等人 [92] 提出了针对基于分页攻击的防御方案。DR.SGX [11] 通过频繁重随机化数据位置来缓解访问模式泄露，但如果飞地程序的内存访问具有可预测性，则仍可能泄露信息。

Telekine [37] 缓解了 GPU TEE 中由 CPU-GPU 通信模式引发的侧信道，这与 Visor 的无感知 CPU-GPU 通信协议类似（尽管后者专为 Visor 的使用场景设计）。

## 安全推理

近期多项研究提出了基于同态加密和 / 或安全多方计算 [112] 的 CNN 推理加密方案 [21,47,56,84,86]。尽管加密方案避免了基于 TEE 的 CNN 推理的缺陷，但后者的速度仍高出多个数量级 [38,98]。

# 11 结论

我们提出了 Visor—— 一种支持隐私保护型视频分析服务的系统。Visor 采用跨 CPU 和 GPU 的混合 TEE 架构，并结合新颖的数据无感知视觉算法。在存在特权攻击者和恶意共租户的情况下，Visor 为视频流和模型提供了强大的机密性和完整性保障。我们对 Visor 的实现表明，在提供该级别安全性的同时，其性能开销有限。
